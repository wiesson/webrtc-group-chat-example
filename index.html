<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0"
    />
    <style>
      :root {
        --fontSystemFont: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          "Helvetica Neue", Arial, sans-serif, "Apple Color Emoji",
          "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
        --fontSerif: Georgia, Cambria, Times New Roman, Times, serif;
        --fontHeadline: "Playfair Display", serif;
        --colorText: #212529;
        --colorYellow: #ffcf04;
        --colorTeal: #cde7e5;
      }

      html {
        box-sizing: border-box;
        font-family: var(--fontSystemFont);
      }

      *,
      :after,
      :before {
        box-sizing: inherit;
      }

      body {
        margin: 0;
        display: grid;
        grid-template-columns: 1fr 1fr;
        overflow-y: scroll;
      }

      video {
        display: block;
        margin: 0;
        padding: 0;
        width: 100%;
        height: 37vw;
        border: 1px solid black;
      }
    </style>

    <script src="https://unpkg.com/socket.io-client@2.3.0/dist/socket.io.js"></script>
    <script>
      /** CONFIG **/
      const SIGNALING_SERVER = "/api";
      const USE_AUDIO = true;
      const USE_VIDEO = true;
      const DEFAULT_CHANNEL = "some-global-channel-name";
      const MUTE_AUDIO_BY_DEFAULT = false;
      const OFFER_OPTIONS = {
        offerToReceiveAudio: 1,
        offerToReceiveVideo: 1,
      };

      /** You should probably use a different stun server doing commercial stuff **/
      /** Also see: https://gist.github.com/zziuni/3741933 **/
      const RTC_CONFIGURATION = {
        iceServers: [
          {
            urls: [
              "stun:stun1.l.google.com:19302",
              "stun:stun2.l.google.com:19302",
            ],
          },
        ],
        iceCandidatePoolSize: 10,
      };
    </script>

    <script>
      let signalingSocket = null; /* our socket.io connection to our webserver */
      let localMediaStream = null; /* our own microphone / webcam */
      let peers = {}; /* keep track of our peer connections, indexed by peer_id (aka socket.io id) */
      let peerMediaElements = {}; /* keep track of our <video>/<audio> tags, indexed by peer_id */

      function init() {
        console.log("Connecting to signaling server");
        signalingSocket = io(SIGNALING_SERVER);
        signalingSocket = io();

        signalingSocket.on("connect", function () {
          console.log("Connected to signaling server");
          setupLocalMedia().then(() =>
            join_chat_channel(DEFAULT_CHANNEL, {
              "whatever-you-want-here": "stuff",
            })
          );
        });

        signalingSocket.on("disconnect", () => {
          console.log("Disconnected from signaling server");
          /* Tear down all of our peer connections and remove all the
           * media divs when we disconnect */
          for (peer_id in peerMediaElements) {
            peerMediaElements[peer_id].remove();
          }
          for (peer_id in peers) {
            peers[peer_id].close();
          }

          peers = {};
          peerMediaElements = {};
        });

        function join_chat_channel(channel, userdata) {
          signalingSocket.emit("join", {
            channel: channel,
            userdata: userdata,
          });
        }

        function part_chat_channel(channel) {
          signalingSocket.emit("part", channel);
        }

        /**
         * When we join a group, our signaling server will send out 'addPeer' events to each pair
         * of users in the group (creating a fully-connected graph of users, ie if there are 6 people
         * in the channel you will connect directly to the other 5, so there will be a total of 15
         * connections in the network).
         */
        signalingSocket.on("addPeer", (config) => {
          console.log("Signaling server said to add peer:", config);
          const peer_id = config.peer_id;

          if (peer_id in peers) {
            /* This could happen if the user joins multiple channels where the other peer is also in. */
            console.log("Already connected to peer ", peer_id);
            return;
          }
          const peerConnection = new RTCPeerConnection(RTC_CONFIGURATION);
          peers[peer_id] = peerConnection;

          const remoteMedia = document.createElement("video");
          remoteMedia.setAttribute("playsinline", "true");
          remoteMedia.setAttribute("autoplay", "true");

          if (MUTE_AUDIO_BY_DEFAULT) {
            // remoteMedia.setAttribute("muted", "true");
          }

          document.body.append(remoteMedia);
          peerMediaElements[peer_id] = remoteMedia;

          peerConnection.addEventListener("icecandidate", (event) => {
            if (event.candidate) {
              signalingSocket.emit("relayICECandidate", {
                peer_id: peer_id,
                ice_candidate: {
                  sdpMLineIndex: event.candidate.sdpMLineIndex,
                  candidate: event.candidate.candidate,
                },
              });
            }
          });

          peerConnection.addEventListener(
            "track",
            ({ transceiver, track, streams }) => {
              console.log(transceiver);
              // todo: investigate for safari
              /* remoteMedia.srcObject = new MediaStream([
              transceiver.receiver.track,
            ]); */
              // remoteMedia.srcObject.addTrack(transceiver.receiver.track);
              track.onunmute = () => {
                // don't set srcObject again if it is already set.
                if (remoteMedia.srcObject) return;
                remoteMedia.srcObject = streams[0];
              };
            }
          );

          localMediaStream
            .getTracks()
            .forEach((track) =>
              peerConnection.addTrack(track, localMediaStream)
            );

          /* Only one side of the peer connection should create the
           * offer, the signaling server picks one to be the offerer.
           * The other user will get a 'sessionDescription' event and will
           * create an offer, then send back an answer 'sessionDescription' to us
           */
          if (config.should_create_offer) {
            console.log("Creating RTC offer to ", peer_id);
            peerConnection
              .createOffer(OFFER_OPTIONS)
              .then((desc) => {
                console.log("Local offer description is: ", desc);
                peerConnection.setLocalDescription(desc).then(() => {
                  signalingSocket.emit("relaySessionDescription", {
                    peer_id: peer_id,
                    session_description: desc,
                  });
                  console.log("Offer setLocalDescription succeeded");
                });
              })
              .catch((err) => console.log("Error sending offer: ", err));
          }
        });

        /**
         * Peers exchange session descriptions which contains information
         * about their audio / video settings and that sort of stuff. First
         * the 'offerer' sends a description to the 'answerer' (with type
         * "offer"), then the answerer sends one back (with type "answer").
         */
        signalingSocket.on("sessionDescription", (config) => {
          console.log("Remote description received: ", config);
          const peer_id = config.peer_id;
          const peer = peers[peer_id];
          const remote_description = config.session_description;
          console.log(remote_description);

          const desc = new RTCSessionDescription(remote_description);
          peer
            .setRemoteDescription(remote_description)
            .then(() => {
              if (remote_description.type === "offer") {
                console.log("Creating answer");
                peer
                  .createAnswer()
                  .then((local_description) => {
                    peer
                      .setLocalDescription(local_description)
                      .then(() => {
                        signalingSocket.emit("relaySessionDescription", {
                          peer_id: peer_id,
                          session_description: local_description,
                        });
                        console.log("Answer setLocalDescription succeeded");
                      })
                      .catch(() => {
                        alert("Answer setLocalDescription failed!");
                      });
                  })
                  .catch((err) => {
                    console.log("Error creating answer: ", err);
                  });
              }
            })
            .catch((err) => {
              console.log("Error creating answer: ", err);
            });
          console.log("Description Object: ", desc);
        });

        /**
         * The offerer will send a number of ICE Candidate blobs to the answerer so they
         * can begin trying to find the best path to one another on the net.
         */
        signalingSocket.on("iceCandidate", async (config) => {
          const peer = peers[config.peer_id];
          const ice_candidate = config.ice_candidate;
          peer
            .addIceCandidate(new RTCIceCandidate(ice_candidate))
            .catch((err) => console.log("error on iceCandidate", err));
        });

        /**
         * When a user leaves a channel (or is disconnected from the
         * signaling server) everyone will recieve a 'removePeer' message
         * telling them to trash the media channels they have open for those
         * that peer. If it was this client that left a channel, they'll also
         * receive the removePeers. If this client was disconnected, they
         * wont receive removePeers, but rather the
         * signalingSocket.on('disconnect') code will kick in and tear down
         * all the peer sessions.
         */
        signalingSocket.on("removePeer", function (config) {
          console.log("Signaling server said to remove peer:", config);
          const peer_id = config.peer_id;
          if (peer_id in peerMediaElements) {
            peerMediaElements[peer_id].remove();
          }
          if (peer_id in peers) {
            peers[peer_id].close();
          }

          delete peers[peer_id];
          delete peerMediaElements[config.peer_id];
        });
      }

      /***********************/
      /** Local media stuff **/
      /***********************/
      async function setupLocalMedia() {
        if (localMediaStream) {
          return Promise.resolve();
        }
        /* Ask user for permission to use the computers microphone and/or camera,
         * attach it to an <audio> or <video> tag if they give us access. */
        console.log("Requesting access to local audio / video inputs");

        return navigator.mediaDevices
          .getUserMedia({ audio: USE_AUDIO, video: USE_VIDEO })
          .then((stream) => {
            appendMediaStreamNode(stream);
            window.stream = stream;
            localMediaStream = stream;
          })
          .catch(function (err) {
            console.log("Access denied for audio/video", err);
            alert(
              "You chose not to provide access to the camera/microphone, demo will not work."
            );
          });
      }

      function appendMediaStreamNode(stream) {
        const media = document.createElement("video");
        media.setAttribute("playsinline", "true");
        media.setAttribute("autoplay", "true");
        media.srcObject = stream;
        document.body.append(media);
        return stream;
      }
    </script>
  </head>
  <body onload="init()"></body>
</html>
